{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['headline', 'title', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/keshavsaraogi/data/wikihowAll.csv\")\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline  \\\n",
      "0  \\nKeep related supplies in the same area.,\\nMa...   \n",
      "1  \\nCreate a sketch in the NeoPopRealist manner ...   \n",
      "2  \\nGet a bachelor’s degree.,\\nEnroll in a studi...   \n",
      "3  \\nStart with some experience or interest in ar...   \n",
      "4  \\nKeep your reference materials, sketches, art...   \n",
      "\n",
      "                                    title  \\\n",
      "0          How to Be an Organized Artist1   \n",
      "1  How to Create a Neopoprealist Art Work   \n",
      "2      How to Be a Visual Effects Artist1   \n",
      "3           How to Become an Art Investor   \n",
      "4          How to Be an Organized Artist2   \n",
      "\n",
      "                                                text  \n",
      "0   If you're a photographer, keep all the necess...  \n",
      "1   See the image for how this drawing develops s...  \n",
      "2   It is possible to become a VFX artist without...  \n",
      "3   The best art investors do their research on t...  \n",
      "4   As you start planning for a project or work, ...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 215365 entries, 0 to 215364\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   headline  214547 non-null  object\n",
      " 1   title     215364 non-null  object\n",
      " 2   text      214294 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.9+ MB\n",
      "None\n",
      "                                                 headline  \\\n",
      "count                                              214547   \n",
      "unique                                             214096   \n",
      "top     \\nAcquire a pot.,\\nGather the ingredients need...   \n",
      "freq                                                   11   \n",
      "\n",
      "                                 title    text  \n",
      "count                           215364  214294  \n",
      "unique                          215364  209178  \n",
      "top     How to Be an Organized Artist1      ,,  \n",
      "freq                                 1     524  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         title  \\\n",
      "0               How to Be an Organized Artist1   \n",
      "1       How to Create a Neopoprealist Art Work   \n",
      "2           How to Be a Visual Effects Artist1   \n",
      "3                How to Become an Art Investor   \n",
      "4               How to Be an Organized Artist2   \n",
      "...                                        ...   \n",
      "215360               How to Pick a Stage Name3   \n",
      "215361               How to Pick a Stage Name4   \n",
      "215362                 How to Identify Prints1   \n",
      "215363                 How to Identify Prints2   \n",
      "215364                 How to Identify Prints3   \n",
      "\n",
      "                                                 headline  \\\n",
      "0       \\nKeep related supplies in the same area.,\\nMa...   \n",
      "1       \\nCreate a sketch in the NeoPopRealist manner ...   \n",
      "2       \\nGet a bachelor’s degree.,\\nEnroll in a studi...   \n",
      "3       \\nStart with some experience or interest in ar...   \n",
      "4       \\nKeep your reference materials, sketches, art...   \n",
      "...                                                   ...   \n",
      "215360  \\nConsider changing the spelling of your name....   \n",
      "215361  \\nTry out your name.,\\nDon’t legally change yo...   \n",
      "215362  \\nUnderstand the process of relief printing.,\\...   \n",
      "215363  \\nUnderstand the process of intaglio printing....   \n",
      "215364  \\nUnderstand the different varieties of lithog...   \n",
      "\n",
      "                                                     text  \n",
      "0        If you're a photographer, keep all the necess...  \n",
      "1        See the image for how this drawing develops s...  \n",
      "2        It is possible to become a VFX artist without...  \n",
      "3        The best art investors do their research on t...  \n",
      "4        As you start planning for a project or work, ...  \n",
      "...                                                   ...  \n",
      "215360   If you have a name that you like, you might f...  \n",
      "215361   Your name might sound great to you when you s...  \n",
      "215362   Relief printing is the oldest and most tradit...  \n",
      "215363   Intaglio is Italian for \"incis­ing,\" and corr...  \n",
      "215364   Lithography is a big term often used to refer...  \n",
      "\n",
      "[214294 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "\n",
    "df = data[['title', 'headline', 'text']].dropna()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_summaries, val_summaries = train_test_split(\n",
    "    df['text'].tolist(), df['headline'].tolist(), test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a795135af534285af92d5062ffdf538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e293b6b1b9f438e99f1ff1a5e908106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9bbdf4ea8f45098fa543f75d2c3243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Load T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, texts, summaries, tokenizer, max_input_length=512, max_output_length=128):\n",
    "        self.texts = texts\n",
    "        self.summaries = summaries\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_text = \"summarize: \" + self.texts[idx]\n",
    "        target_text = self.summaries[idx]\n",
    "        \n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text, truncation=True, padding='max_length', max_length=self.max_input_length, return_tensors=\"pt\"\n",
    "        )\n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text, truncation=True, padding='max_length', max_length=self.max_output_length, return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
    "            'labels': target_encoding['input_ids'].squeeze()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa55fcd88dad41b587a97c0c9ceaa766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad078808ebb4a38a2442491e053275f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e0dd45ca2b4df38d0b1b6af23de2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataLoader\n",
    "train_dataset = SummarizationDataset(train_texts, train_summaries, tokenizer)\n",
    "val_dataset = SummarizationDataset(val_texts, val_summaries, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Load pre-trained T5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n",
    "\n",
    "# Define optimizer & loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, optimizer, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}\")\n",
    "    print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, optimizer, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Function\n",
    "def generate_summary(text):\n",
    "    model.eval()\n",
    "    input_text = \"summarize: \" + text\n",
    "    input_encoding = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "    input_ids = input_encoding['input_ids'].to(device)\n",
    "    attention_mask = input_encoding['attention_mask'].to(device)\n",
    "    \n",
    "    summary_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the summarizer\n",
    "sample_text = \"\"\"\n",
    "WikiHow is a website that provides step-by-step guides on various topics. It is widely used by individuals seeking\n",
    "how-to information, covering subjects such as health, technology, and daily life tips. The platform relies on volunteer \n",
    "contributors and community edits to maintain the accuracy and quality of its articles.\n",
    "\"\"\"\n",
    "print(\"Generated Summary:\", generate_summary(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
